{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtadeScAXwjD",
        "outputId": "cb3bb1de-389a-49be-99b0-bac4e436fc55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: /content/ndvi_filled_option_c_poly.xlsx\n",
            "Cleaning agronomic years...\n",
            "Inconsistent rows corrected: 562\n",
            "Saving cleaned CSV to: /content/ndvi_optionb_cleaned.csv\n",
            "Preparing modeling dataset...\n",
            "Modeling rows: 556\n",
            "Train rows: 527 Test rows: 29 Last year: 2021\n",
            "Training RandomForest (no hyperparameter tuning by default)...\n",
            "Predicting on test set...\n",
            "Evaluation: {'mae': 1.7613868040144838, 'rmse': 2.5331983109728173, 'r2': 0.5183011483152505}\n",
            "Saving model to: /content/rf_optionb_ndvi_model.joblib\n",
            "Saved results summary to: /content/optionb_results_summary.json\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean NDVI dataset, train RandomForest model for Option B, save artifacts.\n",
        "\n",
        "Inputs:\n",
        " - /mnt/data/ndvi_filled_option_c_poly.xlsx\n",
        "\n",
        "Outputs:\n",
        " - /mnt/data/ndvi_optionb_cleaned.csv\n",
        " - /mnt/data/rf_optionb_ndvi_model.joblib\n",
        " - /mnt/data/optionb_results_summary.json\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "INPUT_PATH = \"/content/ndvi_filled_option_c_poly.xlsx\"\n",
        "CLEAN_CSV = \"/content/ndvi_optionb_cleaned.csv\"\n",
        "MODEL_PATH = \"/content/rf_optionb_ndvi_model.joblib\"\n",
        "RESULTS_JSON = \"/content/optionb_results_summary.json\"\n",
        "\n",
        "def load_data(path=INPUT_PATH):\n",
        "    df = pd.read_excel(path)\n",
        "    df.columns = df.columns.str.lower().str.strip()\n",
        "    return df\n",
        "\n",
        "def clean_agronomic_years(df):\n",
        "    # make sure numeric\n",
        "    for col in [\"planting_year\", \"harvest_year\", \"planting_month\", \"harvest_month\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # Find inconsistencies where planting_year > harvest_year\n",
        "    mask = (df[\"planting_year\"].notna()) & (df[\"harvest_year\"].notna()) & (df[\"planting_year\"] > df[\"harvest_year\"])\n",
        "    inconsistent = df[mask].copy()\n",
        "    if not inconsistent.empty:\n",
        "        # Fix: set harvest_year = planting_year (season alignment)\n",
        "        df.loc[mask, \"harvest_year\"] = df.loc[mask, \"planting_year\"]\n",
        "    return df, inconsistent\n",
        "\n",
        "def prepare_modeling_df(df):\n",
        "    # Filter potato rows and necessary features\n",
        "    mask = df[\"product\"].str.lower().str.contains(\"potato\", na=False)\n",
        "    df = df.loc[mask].copy()\n",
        "\n",
        "    # Drop rows missing yield or mean_annual_ndvi\n",
        "    df = df.dropna(subset=[\"yield\", \"mean_annual_ndvi\"]).reset_index(drop=True)\n",
        "\n",
        "    # Ensure numeric types\n",
        "    df[\"area\"] = pd.to_numeric(df[\"area\"], errors=\"coerce\").fillna(0)\n",
        "    df[\"mean_annual_ndvi\"] = pd.to_numeric(df[\"mean_annual_ndvi\"], errors=\"coerce\")\n",
        "\n",
        "    # sort by harvest year chronologically for time split\n",
        "    df = df.sort_values(\"harvest_year\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def build_features(df, encode_county=True, max_dummies=50):\n",
        "    # Basic numeric features\n",
        "    X_num = pd.DataFrame({\n",
        "        \"mean_annual_ndvi\": df[\"mean_annual_ndvi\"].astype(float),\n",
        "        \"area\": df[\"area\"].astype(float),\n",
        "        \"planting_month\": df[\"planting_month\"].fillna(0).astype(int)\n",
        "    })\n",
        "\n",
        "    # Optionally one-hot encode counties if not too many unique\n",
        "    county_col = \"admin_1\"\n",
        "    if encode_county and county_col in df.columns and df[county_col].nunique() <= max_dummies:\n",
        "        dummies = pd.get_dummies(df[county_col].fillna(\"unknown\"), prefix=\"adm1\")\n",
        "        X = pd.concat([X_num.reset_index(drop=True), dummies.reset_index(drop=True)], axis=1)\n",
        "    else:\n",
        "        X = X_num\n",
        "\n",
        "    y = df[\"yield\"].astype(float).values\n",
        "    return X, y\n",
        "\n",
        "def time_train_test_split(df, X, y, time_col=\"harvest_year\"):\n",
        "    years = pd.to_numeric(df[time_col], errors=\"coerce\").astype(\"Int64\")\n",
        "    last_year = int(years.max())\n",
        "    train_mask = years < last_year\n",
        "    test_mask = years == last_year\n",
        "\n",
        "    # If inadequate time-based train size, fallback to random 80/20\n",
        "    if train_mask.sum() < 10 or test_mask.sum() < 5:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    else:\n",
        "        X_train = X.loc[train_mask]\n",
        "        y_train = y[train_mask.values]\n",
        "        X_test = X.loc[test_mask]\n",
        "        y_test = y[test_mask.values]\n",
        "    return X_train, X_test, y_train, y_test, last_year\n",
        "\n",
        "def train_rf(X_train, y_train, do_tune=False):\n",
        "    rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "    if not do_tune:\n",
        "        rf.fit(X_train, y_train)\n",
        "        return rf, None\n",
        "    # Randomized search with TimeSeriesSplit\n",
        "    param_dist = {\n",
        "        \"n_estimators\": [200, 300, 500],\n",
        "        \"max_depth\": [5, 10, 15, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4]\n",
        "    }\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    rnd = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=tscv, scoring=\"neg_mean_absolute_error\", n_jobs=-1, random_state=42)\n",
        "    rnd.fit(X_train, y_train)\n",
        "    best = rnd.best_estimator_\n",
        "    return best, rnd\n",
        "\n",
        "def evaluate(y_test, y_pred):\n",
        "    if len(y_test) == 0:\n",
        "        return {\"mae\": None, \"rmse\": None, \"r2\": None}\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)  # Calculate RMSE manually\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return {\"mae\": float(mae), \"rmse\": float(rmse), \"r2\": float(r2)}\n",
        "\n",
        "def main():\n",
        "    print(\"Loading dataset:\", INPUT_PATH)\n",
        "    df = load_data(INPUT_PATH)\n",
        "\n",
        "    print(\"Cleaning agronomic years...\")\n",
        "    df_clean, inconsistent_rows = clean_agronomic_years(df)\n",
        "    print(\"Inconsistent rows corrected:\", inconsistent_rows.shape[0])\n",
        "\n",
        "    print(\"Saving cleaned CSV to:\", CLEAN_CSV)\n",
        "    df_clean.to_csv(CLEAN_CSV, index=False)\n",
        "\n",
        "    print(\"Preparing modeling dataset...\")\n",
        "    mdl = prepare_modeling_df(df_clean)\n",
        "    print(\"Modeling rows:\", mdl.shape[0])\n",
        "\n",
        "    X, y = build_features(mdl, encode_county=True, max_dummies=100)\n",
        "    X_train, X_test, y_train, y_test, last_year = time_train_test_split(mdl, X, y)\n",
        "\n",
        "    print(\"Train rows:\", X_train.shape[0], \"Test rows:\", X_test.shape[0], \"Last year:\", last_year)\n",
        "\n",
        "    print(\"Training RandomForest (no hyperparameter tuning by default)...\")\n",
        "    rf, rnd_search = train_rf(X_train, y_train, do_tune=False)\n",
        "\n",
        "    print(\"Predicting on test set...\")\n",
        "    y_pred = rf.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
        "\n",
        "    results = evaluate(y_test, y_pred)\n",
        "    print(\"Evaluation:\", results)\n",
        "\n",
        "    # Save model\n",
        "    print(\"Saving model to:\", MODEL_PATH)\n",
        "    joblib.dump(rf, MODEL_PATH)\n",
        "\n",
        "    summary = {\n",
        "        \"input_path\": INPUT_PATH,\n",
        "        \"clean_csv\": CLEAN_CSV,\n",
        "        \"model_path\": MODEL_PATH,\n",
        "        \"n_rows_original\": int(pd.read_excel(INPUT_PATH).shape[0]),\n",
        "        \"n_rows_cleaned\": int(df_clean.shape[0]),\n",
        "        \"n_rows_modeling\": int(mdl.shape[0]),\n",
        "        \"unique_counties\": int(mdl[\"admin_1\"].nunique()),\n",
        "        \"last_harvest_year_used_as_test\": int(last_year),\n",
        "        \"train_rows\": int(X_train.shape[0]),\n",
        "        \"test_rows\": int(X_test.shape[0]),\n",
        "        \"mae\": results[\"mae\"],\n",
        "        \"rmse\": results[\"rmse\"],\n",
        "        \"r2\": results[\"r2\"]\n",
        "    }\n",
        "\n",
        "    with open(RESULTS_JSON, \"w\") as f:\n",
        "        json.dump(summary, f, indent=2)\n",
        "\n",
        "    print(\"Saved results summary to:\", RESULTS_JSON)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}